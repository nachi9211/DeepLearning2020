{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN_MUSIC.iypnb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAJ3QALV9ToS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Check GPU Runtime\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "print(gpu_info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SrXmWc99aBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pre-requisite: If the code is executed in Google Colab, download the dataset and upload it to your google drive in the same location\n",
        "#Dataset: https://drive.google.com/file/d/19kPdA5v7gtAMU5QbIxHxjWj_HdiYPcZf/view?usp=sharing\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCoOOaKWnw_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Required to run after every session timeout\n",
        "pip install librosa --upgrade"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIlWFI459bFd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "59eb194e-7a3a-4866-b500-9e8edd169ba5"
      },
      "source": [
        "## Implementation of DCGAN - as described by Radford et al. 2015\n",
        "#1. Importing required packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "from librosa import display\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Reshape\n",
        "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
        "from keras.layers import LeakyReLU, Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "\n",
        "\n",
        "#2. Constructing MusicDCGAN class that contains the model for the discriminator and generator\n",
        "class MusicDCGAN(object):\n",
        "    def __init__(self, spectogram_time=640, spectogram_frequency=128, channel=1):\n",
        "        self.img_rows = spectogram_frequency\n",
        "        self.img_cols = spectogram_time\n",
        "        self.channel = channel\n",
        "        self.D = None   # discriminator\n",
        "        self.G = None   # generator\n",
        "        self.AM = None  # adversarial model\n",
        "        self.DM = None  # discriminator model\n",
        "\n",
        "    #3. Setting up discriminator model\n",
        "    def discriminator(self):\n",
        "        if self.D:\n",
        "            return self.D\n",
        "        self.D = Sequential()\n",
        "        depth = 128\n",
        "        dropout = 0.4\n",
        "        input_shape = (self.img_rows, self.img_cols, self.channel)\n",
        "        self.D.add(Conv2D(depth*1, 5, strides=2, input_shape=input_shape,\\\n",
        "            padding='same'))\n",
        "        self.D.add(LeakyReLU(alpha=0.2))\n",
        "        self.D.add(Dropout(dropout))\n",
        "\n",
        "        self.D.add(Conv2D(depth*2, 5, strides=2, padding='same'))\n",
        "        self.D.add(LeakyReLU(alpha=0.2))\n",
        "        self.D.add(Dropout(dropout))\n",
        "\n",
        "        self.D.add(Conv2D(depth*4, 5, strides=2, padding='same'))\n",
        "        self.D.add(LeakyReLU(alpha=0.2))\n",
        "        self.D.add(Dropout(dropout))\n",
        "\n",
        "        self.D.add(Conv2D(depth*8, 5, strides=2, padding='same'))\n",
        "        self.D.add(LeakyReLU(alpha=0.2))\n",
        "        self.D.add(Dropout(dropout))\n",
        "\n",
        "        self.D.add(Conv2D(depth*16, 5, strides=2, padding='same'))\n",
        "        self.D.add(LeakyReLU(alpha=0.2))\n",
        "        self.D.add(Dropout(dropout))\n",
        "\n",
        "        self.D.add(Flatten())\n",
        "        self.D.add(Dense(1))\n",
        "        self.D.add(Activation('sigmoid'))\n",
        "        print(\"Discrimnator Summary\")\n",
        "        self.D.summary()\n",
        "        return self.D\n",
        "\n",
        "    #4. Setting up generator model\n",
        "    def generator(self):\n",
        "        if self.G:\n",
        "            return self.G\n",
        "        self.G = Sequential()\n",
        "        dropout = 0.4\n",
        "        depth = 1024\n",
        "        dim = 8\n",
        "        dim2 = 40\n",
        "        self.G.add(Dense(dim*dim2*depth, input_dim=64))\n",
        "        self.G.add(BatchNormalization(momentum=0.9))\n",
        "        self.G.add(Activation('relu'))\n",
        "        self.G.add(Reshape((dim, dim2, depth)))\n",
        "        self.G.add(Dropout(dropout))\n",
        "        self.G.add(UpSampling2D())\n",
        "        self.G.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
        "        self.G.add(BatchNormalization(momentum=0.9))\n",
        "        self.G.add(Activation('relu'))\n",
        "        self.G.add(UpSampling2D())\n",
        "        \n",
        "        self.G.add(Conv2DTranspose(int(depth/4), 5, padding='same'))\n",
        "        self.G.add(BatchNormalization(momentum=0.9))\n",
        "        self.G.add(Activation('relu'))\n",
        "        self.G.add(UpSampling2D())\n",
        "        \n",
        "        self.G.add(Conv2DTranspose(int(depth/8), 5, padding='same'))\n",
        "        self.G.add(BatchNormalization(momentum=0.9))\n",
        "        self.G.add(Activation('relu'))\n",
        "        self.G.add(UpSampling2D())\n",
        "        \n",
        "        #self.G.add(Conv2DTranspose(int(depth/16), 5, padding='same'))\n",
        "        #self.G.add(BatchNormalization(momentum=0.9))\n",
        "        #self.G.add(Activation('relu'))\n",
        "\n",
        "        self.G.add(Conv2DTranspose(1, 5, padding='same'))\n",
        "        self.G.add(Activation('tanh'))\n",
        "        print(\"Generator Summary\")\n",
        "        self.G.summary()\n",
        "        return self.G\n",
        "\n",
        "    #5. Defining discriminator model\n",
        "    def discriminator_model(self):\n",
        "        if self.DM:\n",
        "            return self.DM\n",
        "        optimizer = RMSprop(lr=0.0002, decay=6e-8)\n",
        "        self.DM = Sequential()\n",
        "        self.DM.add(self.discriminator())\n",
        "        self.DM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
        "            metrics=['accuracy'])\n",
        "        return self.DM\n",
        "\n",
        "    #6. Defining generator model\n",
        "    def adversarial_model(self):\n",
        "        if self.AM:\n",
        "            return self.AM\n",
        "        optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
        "        self.AM = Sequential()\n",
        "        self.AM.add(self.generator())\n",
        "        self.AM.add(self.discriminator())\n",
        "        self.AM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
        "            metrics=['accuracy'])\n",
        "        return self.AM\n",
        "\n",
        "#7. Constructing TrainDCGAN class that contains the training algorithm for the models\n",
        "class TrainDCGAN(object):\n",
        "    def __init__(self):\n",
        "        self.img_rows = 128\n",
        "        self.img_cols = 640\n",
        "        #https://drive.google.com/file/d/1vKVt7sd2f8D5aSNxoggcdHbrThHxlXx7/view?usp=sharing - Download file and upload it to Google drive in the same path.\n",
        "        train_data = np.load('/content/drive/My Drive/DL/GAN/shuffled_train.npz')\n",
        "        self.x_train_rot = train_data['arr_0']\n",
        "        size = 999\n",
        "        self.x_train = np.empty((size,self.img_rows,self.img_cols))\n",
        "        for i in range(size):\n",
        "            self.x_train[i,:,:] = np.rot90(self.x_train_rot[i,:,:],3)\n",
        "        print(self.x_train.shape) \n",
        "        self.x_train = self.x_train.reshape(-1, self.img_rows,self.img_cols, 1).astype(np.float32)\n",
        "\n",
        "\n",
        "        #8. Creating objects for MusicDCGAN and calling the models \n",
        "        self.MusicDCGAN = MusicDCGAN()\n",
        "        self.discriminator =  self.MusicDCGAN.discriminator_model()\n",
        "        self.adversarial = self.MusicDCGAN.adversarial_model()\n",
        "        self.generator = self.MusicDCGAN.generator()\n",
        "        self.disc_loss = []\n",
        "        self.gen_loss = []\n",
        "\n",
        "    #9. Defining the training parameters\n",
        "    def train(self, epochs, batch_size, save_interval):\n",
        "        noise_input = None\n",
        "        if save_interval>=0:\n",
        "            noise_input = np.random.uniform(-1.0, 1.0, size=[batch_size, 64])\n",
        "        for i in range(epochs):\n",
        "            #print(\"Input sample data shape and spectrogram\")\n",
        "            #print(self.x_train.shape)\n",
        "            #librosa.display.specshow((self.x_train[np.random.randint(0, 999),:,:,0]), y_axis='mel', fmax=8000, x_axis='time')\n",
        "            #plt.colorbar(format='%+2.0f dB')\n",
        "            #plt.show()    \n",
        "            images_train = self.x_train[np.random.randint(0, self.x_train.shape[0], size=batch_size), :, :, :]\n",
        "            #print(\"Input training data shape and spectrogram\")\n",
        "            #print(images_train.shape)\n",
        "            #librosa.display.specshow(images_train[0,:,:,0], y_axis='mel', fmax=8000, x_axis='time')\n",
        "            #plt.colorbar(format='%+2.0f dB')\n",
        "            #plt.show()            \n",
        "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 64])\n",
        "            images_fake = self.generator.predict(noise)\n",
        "            x = np.concatenate((images_train, images_fake))\n",
        "            y = np.ones([2*batch_size, 1])\n",
        "            y[batch_size:, :] = 0\n",
        "            d_loss = self.discriminator.train_on_batch(x, y)\n",
        "            y = np.ones([batch_size, 1])\n",
        "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 64])\n",
        "            a_loss = self.adversarial.train_on_batch(noise, y)\n",
        "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
        "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
        "            self.disc_loss.append(d_loss[0])\n",
        "            self.gen_loss.append(a_loss[0])\n",
        "            print(log_mesg)\n",
        "            if (i+1)%save_interval==0:\n",
        "              self.generate_spectrogram(noise_input, i)\n",
        "\n",
        "\n",
        "      #10. Generating new spectrogram at given sample interval\n",
        "    def generate_spectrogram(self, noise, epoch):\n",
        "        predictions = self.generator.predict(noise)\n",
        "        print(\"Predicted data shape\")\n",
        "        print(predictions.shape)\n",
        "        print(\"Reshaping Output data\")\n",
        "        generated_seq = np.reshape(predictions[0], (128,640))\n",
        "        print(generated_seq.shape)\n",
        "        self.convert_to_audio(generated_seq, epoch)\n",
        "        librosa.display.specshow(generated_seq, y_axis='mel', fmax=8000, x_axis='time')\n",
        "        plt.colorbar(format='%+2.0f dB')\n",
        "        plt.savefig(\"/content/drive/My Drive/DL/GAN/Results/DCGAN_MUSIC/GeneratedOutputForEpoch-%d.png\" % epoch)\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "      \n",
        "      #11. Generate audio sample from spectogram\n",
        "    def convert_to_audio (self, dbspectogram, epoch):\n",
        "        # db_to_power(S_db) ~= ref * 10.0**(S_db / 10)\n",
        "        audio_spectogram = librosa.core.db_to_power(dbspectogram)\n",
        "        #Converting spectogram into time series array\n",
        "        audio_timeSeries = librosa.feature.inverse.mel_to_audio(audio_spectogram, sr = 22050, hop_length=1024)\n",
        "        #Converting time series array into audio file\n",
        "        audiofile_path = \"/content/drive/My Drive/DL/GAN/Results/DCGAN_MUSIC/GeneratedMusicForEpoch-%d.wav\" % epoch\n",
        "        librosa.output.write_wav(audiofile_path, audio_timeSeries, sr=22050, norm=False)\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I3On6HN9cw9",
        "colab_type": "code",
        "outputId": "b76c6267-d123-48c0-d2ef-f5a7bd9a1420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "mus_dcgan = TrainDCGAN()\n",
        "mus_dcgan.train(epochs=10000, batch_size=32, save_interval=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "372: [D loss: 24.737602, acc: 0.500000]  [A loss: 2497.455566, acc: 0.000000]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}