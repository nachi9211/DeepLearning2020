{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJWH7LUfR3UR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime â†’ \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5UEcazVR4WN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rFHUllv0WOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Implementation of DCGAN - as described by Radford et al. 2015\n",
        "#1. Importing required packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Reshape\n",
        "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
        "from keras.layers import LeakyReLU, Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "\n",
        "\n",
        "#2. Constructing DCGAN class that contains the model for the discriminator and generator\n",
        "class MNISTDCGAN(object):\n",
        "    def __init__(self):\n",
        "        self.D = None   # discriminator\n",
        "        self.G = None   # generator\n",
        "        self.AM = None  # adversarial model\n",
        "        self.DM = None  # discriminator model\n",
        "\n",
        "    #3. Setting up discriminator model\n",
        "    def discriminator(self):\n",
        "        if self.D:\n",
        "            return self.D\n",
        "        self.D = Sequential()\n",
        "        discriminator_filter_size = 64\n",
        "        \n",
        "\n",
        "        dropout = 0.3\n",
        "        #Documentation on the usage of convolutional layers can be found here https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
        "        self.D.add(Conv2D(discriminator_filter_size, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "        self.D.add(LeakyReLU(alpha=0.2))\n",
        "        self.D.add(Dropout(dropout))\n",
        "\n",
        "        self.D.add(Conv2D(discriminator_filter_size*2, 5, strides=2, padding='same'))\n",
        "        self.D.add(LeakyReLU(alpha=0.2))\n",
        "        self.D.add(Dropout(dropout))\n",
        "\n",
        "        self.D.add(Conv2D(discriminator_filter_size*4, 5, strides=2, padding='same'))\n",
        "        self.D.add(LeakyReLU(alpha=0.2))\n",
        "        self.D.add(Dropout(dropout))\n",
        "\n",
        "        self.D.add(Conv2D(discriminator_filter_size*8, 5, strides=1, padding='same'))\n",
        "        self.D.add(LeakyReLU(alpha=0.2))\n",
        "        self.D.add(Dropout(dropout))\n",
        "\n",
        "        # Out: 1-dim probability\n",
        "        self.D.add(Flatten())\n",
        "        self.D.add(Dense(1))\n",
        "        self.D.add(Activation('sigmoid'))\n",
        "        print(\"Discrimnator Summary\")\n",
        "        self.D.summary()\n",
        "        return self.D\n",
        "\n",
        "    #4. Setting up generator model\n",
        "    def generator(self):\n",
        "        if self.G:\n",
        "            return self.G\n",
        "        self.G = Sequential()\n",
        "        dropout = 0.4\n",
        "        generator_filter_size = 256\n",
        "        input_dimension = 7\n",
        "        self.G.add(Dense(input_dimension*input_dimension*generator_filter_size, input_dim=64))\n",
        "        self.G.add(BatchNormalization(momentum=0.9))\n",
        "        self.G.add(Activation('relu'))\n",
        "        self.G.add(Reshape((input_dimension, input_dimension, generator_filter_size)))\n",
        "        self.G.add(Dropout(dropout))\n",
        "        self.G.add(UpSampling2D())\n",
        "        self.G.add(Conv2DTranspose(int(generator_filter_size/2), 5, padding='same'))\n",
        "        self.G.add(BatchNormalization(momentum=0.9))\n",
        "        self.G.add(Activation('relu'))\n",
        "\n",
        "        self.G.add(UpSampling2D())\n",
        "        self.G.add(Conv2DTranspose(int(generator_filter_size/4), 5, padding='same'))\n",
        "        self.G.add(BatchNormalization(momentum=0.9))\n",
        "        self.G.add(Activation('relu'))\n",
        "\n",
        "        self.G.add(Conv2DTranspose(int(generator_filter_size/8), 5, padding='same'))\n",
        "        self.G.add(BatchNormalization(momentum=0.9))\n",
        "        self.G.add(Activation('relu'))\n",
        "\n",
        "        self.G.add(Conv2DTranspose(1, 5, padding='same'))\n",
        "        self.G.add(Activation('tanh'))\n",
        "        print(\"Generator Summary\")\n",
        "        self.G.summary()\n",
        "        return self.G\n",
        "\n",
        "    #5. Defining discriminator model\n",
        "    def discriminator_model(self):\n",
        "        if self.DM:\n",
        "            return self.DM\n",
        "        optimizer = RMSprop(lr=0.0002, decay=6e-8)\n",
        "        self.DM = Sequential()\n",
        "        self.DM.add(self.discriminator())\n",
        "        self.DM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
        "            metrics=['accuracy'])\n",
        "        return self.DM\n",
        "\n",
        "    #6. Defining generator model\n",
        "    def adversarial_model(self):\n",
        "        if self.AM:\n",
        "            return self.AM\n",
        "        optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
        "        self.AM = Sequential()\n",
        "        self.AM.add(self.generator())\n",
        "        self.AM.add(self.discriminator())\n",
        "        self.AM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
        "            metrics=['accuracy'])\n",
        "        return self.AM\n",
        "\n",
        "#7. Constructing  class that contains the training algorithm for the models\n",
        "class TrainDCGAN(object):\n",
        "    def __init__(self):\n",
        "        '''\n",
        "        Usage documentation can be found here: https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data\n",
        "        Since this is a unsupervised learning and we wanted only the training images, we ignored to load other x_test, y_train and y_test.\n",
        "        '''\n",
        "        (self.x_train, _), (_, _) = mnist.load_data(path=\"mnist.npz\")\n",
        "        self.x_train = self.x_train / 127.5 - 1.\n",
        "        self.x_train = np.expand_dims(self.x_train, axis=3)\n",
        "\n",
        "        #8. Creating objects for DCGAN and calling the models \n",
        "        self.DCGAN = MNISTDCGAN()\n",
        "        self.discriminator =  self.DCGAN.discriminator_model()\n",
        "        self.adversarial = self.DCGAN.adversarial_model()\n",
        "        self.generator = self.DCGAN.generator()\n",
        "        self.disc_loss = []\n",
        "        self.gen_loss = []\n",
        "\n",
        "    #9. Defining the training parameters\n",
        "    def train(self, epochs, batch_size=256, save_interval=1000):\n",
        "        noise_input = None\n",
        "        if save_interval>0:\n",
        "            noise_input = np.random.uniform(-1.0, 1.0, size=[batch_size, 64])\n",
        "        for i in range(epochs):\n",
        "            images_train = self.x_train[np.random.randint(0, self.x_train.shape[0], size=batch_size), :, :, :]\n",
        "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 64])\n",
        "            images_fake = self.generator.predict(noise)\n",
        "            x = np.concatenate((images_train, images_fake))\n",
        "            y = np.ones([2*batch_size, 1])\n",
        "            y[batch_size:, :] = 0\n",
        "            d_loss = self.discriminator.train_on_batch(x, y)\n",
        "            y = np.ones([batch_size, 1])\n",
        "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 64])\n",
        "            a_loss = self.adversarial.train_on_batch(noise, y)\n",
        "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
        "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
        "            self.disc_loss.append(d_loss[0])\n",
        "            self.gen_loss.append(a_loss[0])\n",
        "            print(log_mesg)\n",
        "            if (i+1)%save_interval==0:\n",
        "              self.generate_numbers(i)\n",
        "\n",
        "\n",
        "    #10. Generating new numbers at given sample interval\n",
        "    def generate_numbers(self, epoch):\n",
        "        input_noise = np.random.normal(0, 1, (1, 64))\n",
        "        predictions = self.generator.predict(input_noise)\n",
        "        print(predictions.shape)\n",
        "        print(\"Reshaping Output data\")\n",
        "        generated_seq = np.reshape(predictions[0], (28,28))\n",
        "        print(generated_seq.shape)\n",
        "        plt.figure(figsize = (5,5))\n",
        "        plt.imshow(generated_seq,aspect='auto',cmap='gray')\n",
        "        #Path to be created in Google Drive to avoid failure\n",
        "        plt.savefig(\"/content/drive/My Drive/DL/GAN/Results/DCGAN_MNIST/Epoch-%d.png\" % epoch)\n",
        "        plt.show()\n",
        "        plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSDQZxHU0xxI",
        "colab_type": "code",
        "outputId": "5765b478-1a07-4ef1-fd34-237e4977b8fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899
        }
      },
      "source": [
        "gan = TrainDCGAN()\n",
        "gan.train(epochs=10000, batch_size=32, save_interval=200)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8872: [D loss: 0.727026, acc: 0.468750]  [A loss: 0.954047, acc: 0.031250]\n",
            "8873: [D loss: 0.654934, acc: 0.609375]  [A loss: 0.827100, acc: 0.281250]\n",
            "8874: [D loss: 0.701516, acc: 0.578125]  [A loss: 0.814974, acc: 0.250000]\n",
            "8875: [D loss: 0.694074, acc: 0.453125]  [A loss: 0.821690, acc: 0.218750]\n",
            "8876: [D loss: 0.708722, acc: 0.500000]  [A loss: 0.966682, acc: 0.093750]\n",
            "8877: [D loss: 0.717014, acc: 0.515625]  [A loss: 0.839943, acc: 0.281250]\n",
            "8878: [D loss: 0.689192, acc: 0.515625]  [A loss: 1.066706, acc: 0.000000]\n",
            "8879: [D loss: 0.701796, acc: 0.484375]  [A loss: 0.857499, acc: 0.093750]\n",
            "8880: [D loss: 0.729980, acc: 0.500000]  [A loss: 0.995060, acc: 0.031250]\n",
            "8881: [D loss: 0.740303, acc: 0.500000]  [A loss: 0.789582, acc: 0.343750]\n",
            "8882: [D loss: 0.678550, acc: 0.593750]  [A loss: 1.022691, acc: 0.062500]\n",
            "8883: [D loss: 0.710086, acc: 0.531250]  [A loss: 0.790411, acc: 0.281250]\n",
            "8884: [D loss: 0.696399, acc: 0.578125]  [A loss: 0.904277, acc: 0.093750]\n",
            "8885: [D loss: 0.716777, acc: 0.437500]  [A loss: 0.777270, acc: 0.375000]\n",
            "8886: [D loss: 0.725074, acc: 0.515625]  [A loss: 1.037183, acc: 0.062500]\n",
            "8887: [D loss: 0.696506, acc: 0.500000]  [A loss: 0.786457, acc: 0.312500]\n",
            "8888: [D loss: 0.727892, acc: 0.515625]  [A loss: 1.122648, acc: 0.000000]\n",
            "8889: [D loss: 0.670766, acc: 0.578125]  [A loss: 0.691921, acc: 0.437500]\n",
            "8890: [D loss: 0.694637, acc: 0.531250]  [A loss: 1.363993, acc: 0.000000]\n",
            "8891: [D loss: 0.715579, acc: 0.546875]  [A loss: 0.605776, acc: 0.750000]\n",
            "8892: [D loss: 0.736041, acc: 0.515625]  [A loss: 1.059824, acc: 0.062500]\n",
            "8893: [D loss: 0.664149, acc: 0.546875]  [A loss: 0.654454, acc: 0.562500]\n",
            "8894: [D loss: 0.755312, acc: 0.500000]  [A loss: 0.948559, acc: 0.156250]\n",
            "8895: [D loss: 0.739439, acc: 0.437500]  [A loss: 0.864198, acc: 0.218750]\n",
            "8896: [D loss: 0.662504, acc: 0.609375]  [A loss: 1.012408, acc: 0.125000]\n",
            "8897: [D loss: 0.682283, acc: 0.609375]  [A loss: 0.908777, acc: 0.156250]\n",
            "8898: [D loss: 0.689354, acc: 0.515625]  [A loss: 0.701162, acc: 0.468750]\n",
            "8899: [D loss: 0.750754, acc: 0.453125]  [A loss: 0.890558, acc: 0.218750]\n",
            "8900: [D loss: 0.696800, acc: 0.515625]  [A loss: 0.872209, acc: 0.250000]\n",
            "8901: [D loss: 0.736041, acc: 0.500000]  [A loss: 0.883468, acc: 0.281250]\n",
            "8902: [D loss: 0.706282, acc: 0.484375]  [A loss: 0.827002, acc: 0.125000]\n",
            "8903: [D loss: 0.757970, acc: 0.421875]  [A loss: 0.846515, acc: 0.187500]\n",
            "8904: [D loss: 0.736703, acc: 0.546875]  [A loss: 1.028713, acc: 0.000000]\n",
            "8905: [D loss: 0.661919, acc: 0.593750]  [A loss: 0.718866, acc: 0.406250]\n",
            "8906: [D loss: 0.726173, acc: 0.500000]  [A loss: 1.065800, acc: 0.031250]\n",
            "8907: [D loss: 0.697194, acc: 0.531250]  [A loss: 0.725779, acc: 0.468750]\n",
            "8908: [D loss: 0.721893, acc: 0.500000]  [A loss: 0.975040, acc: 0.125000]\n",
            "8909: [D loss: 0.748361, acc: 0.515625]  [A loss: 0.933214, acc: 0.062500]\n",
            "8910: [D loss: 0.670572, acc: 0.609375]  [A loss: 0.764090, acc: 0.343750]\n",
            "8911: [D loss: 0.700159, acc: 0.531250]  [A loss: 0.943282, acc: 0.031250]\n",
            "8912: [D loss: 0.703864, acc: 0.531250]  [A loss: 0.771364, acc: 0.406250]\n",
            "8913: [D loss: 0.717547, acc: 0.468750]  [A loss: 0.897035, acc: 0.218750]\n",
            "8914: [D loss: 0.761018, acc: 0.437500]  [A loss: 0.962766, acc: 0.093750]\n",
            "8915: [D loss: 0.664748, acc: 0.562500]  [A loss: 0.828834, acc: 0.250000]\n",
            "8916: [D loss: 0.777374, acc: 0.437500]  [A loss: 1.044759, acc: 0.062500]\n",
            "8917: [D loss: 0.664118, acc: 0.578125]  [A loss: 0.748365, acc: 0.343750]\n",
            "8918: [D loss: 0.731689, acc: 0.515625]  [A loss: 0.936671, acc: 0.125000]\n",
            "8919: [D loss: 0.708987, acc: 0.531250]  [A loss: 0.910962, acc: 0.062500]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}