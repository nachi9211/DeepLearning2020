{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN_MUSIC.ipynb","provenance":[{"file_id":"1js8FNeSo0gISMM4pQSopd3VSOyQvBXlS","timestamp":1589122361198}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"JIvYlPPeIACs","colab_type":"code","outputId":"37431b5a-b424-4522-cc74-ff576c8bb900","executionInfo":{"status":"ok","timestamp":1589141825239,"user_tz":-120,"elapsed":1789,"user":{"displayName":"B.K. Musuadhi Rajan","photoUrl":"","userId":"14130722145672801802"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, \n","and then re-execute this cell.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"trxENaMx-zOG","colab_type":"code","outputId":"d800d0e8-dd82-4df9-ab15-cdafff5ac238","executionInfo":{"status":"ok","timestamp":1589143199109,"user_tz":-120,"elapsed":15992,"user":{"displayName":"B.K. Musuadhi Rajan","photoUrl":"","userId":"14130722145672801802"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["#Pre-requisite: If the code is executed in Google Colab, download the dataset and upload it to your google drive in the same location\n","#Dataset: https://drive.google.com/file/d/19kPdA5v7gtAMU5QbIxHxjWj_HdiYPcZf/view?usp=sharing\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gRKADrSIvCnB","colab_type":"code","colab":{}},"source":["## Implementation of Baseline GAN \n","#1. Importing required packages\n","from keras.datasets import mnist\n","from keras.layers import Input, Dense, Reshape, Flatten\n","from keras.layers import BatchNormalization\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.models import Sequential, Model\n","from tensorflow.keras.optimizers import Adam\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","#2. Constructing MusGAN class\n","class MusGAN():\n","  def __init__(self):\n","    self.img_rows = 640\n","    self.img_cols = 128\n","    self.channels = 1\n","    self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","    self.latent_dim = 64\n","    self.discriminator_lr = 0.0002\n","    self.generator_lr = 0.001\n","    self.discriminator = self.build_discriminator()\n","    self.discriminator.compile(loss='binary_crossentropy',\n","                                optimizer=Adam(self.discriminator_lr, 0.5),\n","                                metrics=['accuracy'])\n","    self.generator = self.build_generator()\n","    z = Input(shape=(self.latent_dim,))\n","    gen_img = self.generator(z)\n","    self.discriminator.trainable = False\n","    validity = self.discriminator(gen_img)\n","    self.combined = Model(z, validity)\n","    self.combined.compile(loss='binary_crossentropy', optimizer=Adam(self.generator_lr, 0.5))\n","\n","#3. Defining generator model\n","  def build_generator(self):\n","    model = Sequential()\n","    model.add(Dense(256, input_dim=self.latent_dim))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(BatchNormalization(momentum=0.8))\n","    model.add(Dense(512))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(BatchNormalization(momentum=0.8))\n","    model.add(Dense(1024))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(BatchNormalization(momentum=0.8))\n","    model.add(Dense(2048))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(BatchNormalization(momentum=0.8))\n","    model.add(Dense(4096))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(BatchNormalization(momentum=0.8))\n","    model.add(Dense(8192))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(BatchNormalization(momentum=0.8))\n","    model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n","    model.add(Reshape(self.img_shape))\n","    noise = Input(shape=(self.latent_dim,))\n","    img = model(noise)\n","    print(\"Generator Summary\")\n","    model.summary()\n","    return Model(noise, img)\n","\n","#4. Defining discriminator model\n","  def build_discriminator(self):\n","    model = Sequential()\n","    model.add(Flatten(input_shape=self.img_shape))\n","    model.add(Dense(8192))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(Dense(4096))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(Dense(2048))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(Dense(1024))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(Dense(512))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(Dense(256))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(Dense(1, activation='sigmoid'))\n","    img = Input(shape=self.img_shape)\n","    validity = model(img)\n","    print(\"Discrimnator Summary\")\n","    model.summary()\n","    return Model(img, validity)\n","\n","#5. Defining the training parameters\n","  def train(self, epochs, batch_size=32, sample_interval=5000):\n","    train_data = np.load('/content/drive/My Drive/DL/FMA/shuffled_train.npz')\n","    self.X_train = train_data['arr_0']\n","    self.X_train = self.X_train / 127.5 - 1.\n","    self.X_train = np.expand_dims(self.X_train, axis=3)\n","    valid = np.ones((batch_size, 1))\n","    fake = np.zeros((batch_size, 1))\n","    for epoch in range(epochs):\n","      idx = np.random.randint(0, self.X_train.shape[0], batch_size)\n","      real_seqs = self.X_train[idx]\n","      noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","      g_loss = self.combined.train_on_batch(noise, valid)\n","      gen_seqs = self.generator.predict(noise)\n","      d_loss_real = self.discriminator.train_on_batch(real_seqs, valid)\n","      d_loss_fake = self.discriminator.train_on_batch(gen_seqs, fake)\n","      d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","      print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n","      if epoch % sample_interval == 0:\n","        self.sample_images(epoch)\n","\n","#6. Method to generate new image at given sample interval\n","  def sample_images(self, epoch):\n","        predictions = self.generator.predict(noise)\n","        print(predictions.shape)\n","        print(\"Reshaping Output data\")\n","        generated_seq = np.reshape(predictions[0], (640,128))\n","        print(\"Transforming Output data\")\n","        generated_seq = np.rot90(generated_seq,3)\n","        print(generated_seq.shape)\n","        self.convert_to_audio(generated_seq, epoch)\n","        librosa.display.specshow(generated_seq, y_axis='mel', fmax=8000, x_axis='time')\n","        plt.colorbar(format='%+2.0f dB')\n","        plt.savefig(\"/content/drive/My Drive/DL/GAN/Results/GAN_MUSIC/%d.png\" % epoch)\n","        plt.show()\n","        plt.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FJ35RIFk6B8D","colab_type":"code","outputId":"477d4f79-949e-452a-fe17-565aa85e8c69","executionInfo":{"status":"ok","timestamp":1589123610746,"user_tz":-330,"elapsed":154413,"user":{"displayName":"B.K. Musuadhi Rajan","photoUrl":"","userId":"14130722145672801802"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#7. Begin training\n","gan = MusGAN()    \n","gan.train(epochs=10, batch_size=32, sample_interval=2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Discrimnator Summary\n","Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten_2 (Flatten)          (None, 81920)             0         \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 8192)              671096832 \n","_________________________________________________________________\n","leaky_re_lu_13 (LeakyReLU)   (None, 8192)              0         \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 4096)              33558528  \n","_________________________________________________________________\n","leaky_re_lu_14 (LeakyReLU)   (None, 4096)              0         \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 2048)              8390656   \n","_________________________________________________________________\n","leaky_re_lu_15 (LeakyReLU)   (None, 2048)              0         \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 1024)              2098176   \n","_________________________________________________________________\n","leaky_re_lu_16 (LeakyReLU)   (None, 1024)              0         \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 512)               524800    \n","_________________________________________________________________\n","leaky_re_lu_17 (LeakyReLU)   (None, 512)               0         \n","_________________________________________________________________\n","dense_20 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","leaky_re_lu_18 (LeakyReLU)   (None, 256)               0         \n","_________________________________________________________________\n","dense_21 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 715,800,577\n","Trainable params: 715,800,577\n","Non-trainable params: 0\n","_________________________________________________________________\n","Generator Summary\n","Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_22 (Dense)             (None, 256)               16640     \n","_________________________________________________________________\n","leaky_re_lu_19 (LeakyReLU)   (None, 256)               0         \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 256)               1024      \n","_________________________________________________________________\n","dense_23 (Dense)             (None, 512)               131584    \n","_________________________________________________________________\n","leaky_re_lu_20 (LeakyReLU)   (None, 512)               0         \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 512)               2048      \n","_________________________________________________________________\n","dense_24 (Dense)             (None, 1024)              525312    \n","_________________________________________________________________\n","leaky_re_lu_21 (LeakyReLU)   (None, 1024)              0         \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 1024)              4096      \n","_________________________________________________________________\n","dense_25 (Dense)             (None, 2048)              2099200   \n","_________________________________________________________________\n","leaky_re_lu_22 (LeakyReLU)   (None, 2048)              0         \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, 2048)              8192      \n","_________________________________________________________________\n","dense_26 (Dense)             (None, 4096)              8392704   \n","_________________________________________________________________\n","leaky_re_lu_23 (LeakyReLU)   (None, 4096)              0         \n","_________________________________________________________________\n","batch_normalization_11 (Batc (None, 4096)              16384     \n","_________________________________________________________________\n","dense_27 (Dense)             (None, 8192)              33562624  \n","_________________________________________________________________\n","leaky_re_lu_24 (LeakyReLU)   (None, 8192)              0         \n","_________________________________________________________________\n","batch_normalization_12 (Batc (None, 8192)              32768     \n","_________________________________________________________________\n","dense_28 (Dense)             (None, 81920)             671170560 \n","_________________________________________________________________\n","reshape_2 (Reshape)          (None, 640, 128, 1)       0         \n","=================================================================\n","Total params: 715,963,136\n","Trainable params: 715,930,880\n","Non-trainable params: 32,256\n","_________________________________________________________________\n"],"name":"stdout"}]}]}